{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "x = tf.constant(np.random.uniform(size =(2,m)), dtype = tf.float32)\n",
    "y = tf.constant(np.random.randint(2,size =(1,m)), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.constant(np.random.uniform(size =(4, 2)), dtype = tf.float32)\n",
    "b1 = tf.constant(np.zeros(shape = (4, 1)), dtype = tf.float32)\n",
    "\n",
    "w2 = tf.constant(np.random.uniform(size =(4, 4)), dtype = tf.float32)\n",
    "b2 = tf.constant(np.zeros(shape = (4, 1)), dtype = tf.float32)\n",
    "\n",
    "w3 = tf.constant(np.random.uniform(size =(1, 4)), dtype = tf.float32)\n",
    "b3 = tf.constant(np.zeros(shape = (1, 1)), dtype = tf.float32)\n",
    "\n",
    "# class Weights():\n",
    "#     def __init__(self, Nunits, kernel_fn = 'random', bias_fn = 'zeros'):\n",
    "#         self.Nunits = Nunits\n",
    "#         self.init_fn = init_fn\n",
    "        \n",
    "#     def __call__(self):\n",
    "#         self.weights = []\n",
    "#         for u in range(1,len(Nunits)):\n",
    "#             w = self.random((Nunits[u],Nunits[u - 1]))\n",
    "#             b = self.zero((Nunits[u],1))\n",
    "#             self.weights.append(w)\n",
    "#             self.weights.append(b)\n",
    "            \n",
    "#     def random(self, shape):\n",
    "#         return tf.random.uniform(shape = shape)\n",
    "    \n",
    "#     def zero(self, shape):\n",
    "#         return tf.zeros(shape = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Derivative():\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "    \n",
    "    def __call__(self, *args):\n",
    "        return getattr(Derivative, self.function)(*args)\n",
    "    \n",
    "    def sigmoid(A):\n",
    "        return A * (1 - A)\n",
    "    \n",
    "    def tanh(A):\n",
    "        return 1 - A ** 2\n",
    "    \n",
    "    def binary_crossentropy(Y, A):\n",
    "        return - (Y / A) + ((1 - Y) / (1 - A))\n",
    "\n",
    "# test_in = tf.constant(np.random.uniform(size =(4, 2)), dtype = tf.float32)    \n",
    "# Derivative('tanh')(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    def __init__(self, units, activation, weights, bias):\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return self.forward_step(X)\n",
    "        \n",
    "    def forward_step(self, X):\n",
    "        self.Z = tf.matmul(self.weights, X) + self.bias\n",
    "        \n",
    "        if self.activation == 'sigmoid':\n",
    "            self.A = tf.math.sigmoid(self.Z)\n",
    "            return self.A\n",
    "        elif self.activation == 'tanh':\n",
    "            self.A = tf.math.tanh(self.Z)\n",
    "            return self.A\n",
    "        \n",
    "    def backward_step(self, dA, A_prev, m):\n",
    "        self.dz = dA * Derivative(self.activation)(self.A)\n",
    "        self.dw = tf.matmul(self.dz, A_prev, transpose_b = True) / m\n",
    "        self.db = tf.reduce_sum(self.dz, axis = 1, keepdims = True) / m\n",
    "        return tf.matmul(self.weights, self.dz, transpose_a = True)\n",
    "            \n",
    "        \n",
    "    def update_weights_and_biases(self, lr):\n",
    "        self.weights = self.weights - lr * self.dw\n",
    "        self.bias = self.bias - lr * self.db\n",
    "            \n",
    "    def get_z(self):\n",
    "        return self.Z\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights, self.bias\n",
    "    \n",
    "# h1 = Dense(units = 4, activation = 'tanh', weights = w1, bias = b1)\n",
    "# h2 = Dense(units = 4, activation = 'tanh', weights = w2, bias = b2)\n",
    "# o1 = Dense(units = 1, activation = 'sigmoid', weights = w3, bias = b3)            \n",
    "# o1(h2(h1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,layers, lossfn, lr):\n",
    "        self.lossfn = lossfn\n",
    "        self.lr = lr\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __call__(self,X):\n",
    "        return self.forward_propagation(X)\n",
    "        \n",
    "    def forward_propagation(self, A):\n",
    "        self.all_activations = []\n",
    "        self.all_activations.append(A)\n",
    "        for layer in self.layers:\n",
    "            A = layer(A)\n",
    "            self.all_activations.append(A)\n",
    "        return self.all_activations[-1]\n",
    "    \n",
    "    def backward_propagation(self, Y):\n",
    "        self.m = Y.shape[1]\n",
    "        dA = Derivative(self.lossfn)(Y, self.all_activations[-1])\n",
    "        for l in reversed(range(len(self.layers))):\n",
    "            dA = self.layers[l].backward_step(dA, self.all_activations[l], self.m)\n",
    "            self.layers[l].update_weights_and_biases(self.lr)\n",
    "\n",
    "# h1 = Dense(units = 4, activation = 'tanh', weights = w1, bias = b1)\n",
    "# h2 = Dense(units = 4, activation = 'tanh', weights = w2, bias = b2)\n",
    "# o1 = Dense(units = 1, activation = 'sigmoid', weights = w3, bias = b3)            \n",
    "# layers = [h1, h2, o1]\n",
    "# model = Model(layers, 'binary_crossentropy', 0.1)\n",
    "# model(x)     \n",
    "# model.backward_propagation(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = Dense(units = 4, activation = 'tanh', weights = w1, bias = b1)\n",
    "h2 = Dense(units = 4, activation = 'tanh', weights = w2, bias = b2)\n",
    "o1 = Dense(units = 1, activation = 'sigmoid', weights = w3, bias = b3)            \n",
    "layers = [h1, h2, o1]\n",
    "model = Model(layers, 'binary_crossentropy', 0.1)\n",
    "\n",
    "EPOCHS = 10\n",
    "for i in range(EPOCHS):\n",
    "    y_hat = model(x)\n",
    "    loss = tf.squeeze((tf.matmul(y,tf.math.log(y_hat), transpose_b = True) + tf.matmul(1 - y,tf.math.log(1 - y_hat), transpose_b = True)) * (-1/y.shape[1]))\n",
    "    model.backward_propagation(y)\n",
    "    print('Epoch: {}   loss: {}'.format(i+1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras to get same results\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units = 4,activation = 'tanh',  name = 'd1', input_shape = (x.shape[0],)))\n",
    "    model.add(tf.keras.layers.Dense(units = 4,activation = 'tanh',  name = 'd2'))\n",
    "    model.add(tf.keras.layers.Dense(units = 1,activation = 'sigmoid',  name = 'o1'))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
    "                loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model = create_model()\n",
    "\n",
    "d1 = model.get_layer('d1')\n",
    "d1_weights = [tf.constant(tf.transpose(w1), dtype = tf.float32), tf.constant(tf.squeeze(b1), dtype = tf.float32)]\n",
    "d1.set_weights(d1_weights)\n",
    "\n",
    "d2 = model.get_layer('d2')\n",
    "d2_weights = [tf.constant(tf.transpose(w2), dtype = tf.float32), tf.constant(tf.squeeze(b2), dtype = tf.float32)]\n",
    "d2.set_weights(d2_weights)\n",
    "\n",
    "\n",
    "o1 = model.get_layer('o1')\n",
    "o1_weights = [tf.constant(tf.transpose(w3), dtype = tf.float32), tf.constant(tf.squeeze(b3, axis = 1), dtype = tf.float32)]\n",
    "o1.set_weights(o1_weights)\n",
    "\n",
    "xt = tf.transpose(x)\n",
    "yt = tf.transpose(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xt, yt, epochs = 10, batch_size = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
